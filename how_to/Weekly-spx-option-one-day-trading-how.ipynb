{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "[SMB capital video: combining credit spread with a good one-day directional signal](https://www.youtube.com/watch?v=qabKcPmwjEA)\n",
    "\n",
    "[How to use bs to scrape technical analysis signal for different time frames from investing.com](https://stackoverflow.com/a/57490089/15373476)\n",
    "\n",
    "[Don't use this strategy on AM settled index options (monthly) - why](https://support.tastyworks.com/support/solutions/articles/43000435308-settlement-and-expiration-of-cash-settled-index-options)\n",
    "\n",
    "[cash-settled index options specifications (monthly/weekly)](https://support.tastyworks.com/support/solutions/articles/43000435289?_sp=aec5afae-5774-4ba0-a71c-801743f9e2cb.1643836338440)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Directional Signal from Investing.com\n",
    "\n",
    "I will use the daily and weekly TA signals provided by www.investing.com. The website updates these signals about the close of market (`03:59PM GMT`). \n",
    "\n",
    "The following code scrape the signals data from the website and store to the csv file.\n",
    "\n",
    "### How to scrape\n",
    "\n",
    "The website generates signals for different periods with JavaScript. I followed the following steps to accomplish the task of scraping:\n",
    "\n",
    "- Use dev tool to inspect the network activity of SPX's TA webpage, e.g. the activities trigerred by clicking the links of \"5 hour\", \"daily\" or \"weekly\":\n",
    "    - Use `Network` tab in the dev tool\n",
    "    - press `Clear` button to clear existing activity logs, so it's easier to observe the new logs triggered by the action\n",
    "    - `headers` and `payload` show the information required to create the `POST` request later\n",
    "    - `response` shows the elements that contain the signal data\n",
    "    \n",
    "    \n",
    "- Use the data found in `headers` and `payload` to create a `POST` request to send to the website server, and a response shall be returned from the server, which contains a new HTML string. Parse this string to extract the signal data.\n",
    "\n",
    "\n",
    "- Repeat the above step for all periods desired.\n",
    "\n",
    "\n",
    "### Run Script Automatically on Schedule using `cron`\n",
    "\n",
    "**The following script is saved under `/data_pipelines/ta_signals.py`**, it's run in the conda virtual environment of `quantra`. I use `cron` to schedule the script to run at:\n",
    "\n",
    "- 6:30 am Mon-Fri (open of the market)\n",
    "- 1:00 pm Mon-Fri (close of the market)\n",
    "\n",
    "In order for `cron` to know the script shall run with the Python in the virual env, I added `!/Users/catelinn/miniconda3/envs/quantra/bin/python` at the very top of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/Users/catelinn/miniconda3/envs/quantra/bin/python\n",
    "'''\n",
    "Scrape the technical analysis data from www.investing.com\n",
    "for indices such as SPX and DJA.\n",
    "'''\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "\n",
    "\n",
    "# Asset's pairID and period codes\n",
    "# can be found in `payload` tab in the network log details    \n",
    "periodLabels = {'5hr': 18000, 'daily': 86400, 'weekly': 'week'}\n",
    "pairIDs = {'SPX': 166, 'DJA': 169}\n",
    "urls = {'SPX':'https://www.investing.com/technical/us-spx-500-technical-analysis', \n",
    "        'DJA': 'https://www.investing.com/technical/dj-30-indices-technical-analysis'}\n",
    "\n",
    "\n",
    "# Simulate post request to have the web server generate TA signal page\n",
    "# for specified pair and period,\n",
    "# which shall be returned in the response HTML\n",
    "def fetch(pair:str='SPX', period:str ='weekly')-> list:\n",
    "    \n",
    "    # headers information can be found in Chrome dev tool -> 'network' tab\n",
    "    headers = { 'User-Agent': 'Mozilla/5.0',\n",
    "                'Content-Type': 'application/x-www-form-urlencoded',\n",
    "                'Referer': urls[pair],\n",
    "                'X-Requested-With': 'XMLHttpRequest'}\n",
    "    \n",
    "    body = {'pairID' : pairIDs[pair], 'period': periodLabels[period], 'viewType' : 'normal'}\n",
    "    \n",
    "    with requests.Session() as s:\n",
    "        # send post request\n",
    "        r = s.post('https://www.investing.com/technical/Service/GetStudiesContent', \n",
    "                   data = body, headers = headers)\n",
    "        # parse the response\n",
    "        soup = bs(r.content, 'lxml')\n",
    "        signal = soup.select('#techStudiesInnerWrap .summary')[-1].select('span')[-1].text # the signal\n",
    "        date = re.sub('M.*$', 'M', soup.find('div', id='updateTime').text) # when the signal last updated by the website\n",
    "    \n",
    "    return [pair, period, signal, date]\n",
    "    \n",
    "#print(fetch(period='daily'))\n",
    "\n",
    "def save(data:list)-> None:\n",
    "    \n",
    "    import os\n",
    "    f_path = '/Volumes/ExtremeSSD/github_repos/01_Trading_app_projects/data_pipelines/outputs/signals.csv'\n",
    "    \n",
    "    if os.path.isfile(f_path):\n",
    "        with open(f_path, 'a') as f:\n",
    "            f.write(','.join([str(i) for i in data])+'\\n')\n",
    "    else:\n",
    "        with open(f_path, 'w') as f:\n",
    "            f.write(','.join([str(i) for i in data])+'\\n')\n",
    "\n",
    "periods = ['daily', 'weekly']\n",
    "pairs = ['SPX', 'DJA']\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    for pair in pairs:\n",
    "        for period in periods:\n",
    "            data = fetch(pair, period)\n",
    "            save(data)\n",
    "            print(f'{data[0]} for {data[1]} updated on {data[3]}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quantra",
   "language": "python",
   "name": "quantra"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
